substitutions:
  _DATAFLOW_JAR_BUCKET: "${PROJECT_ID}-artifacts"
  _DATAFLOW_STAGING_BUCKET: "${PROJECT_ID}-artifacts-staging"
  _COMPOSER_REGION: 'us-central1'
  _COMPOSER_ZONE_ID: 'us-central1-a'
  _COMPOSER_ENV_NAME: 'dlp-pipeline-composer'
  _COMPOSER_DAG_NAME: 'db-import'
steps:
  - name: gcr.io/cloud-builders/git
    args: [ 'clone', 'https://github.com/arwasanawadwala/dlp-rdb-bq-import.git' ]
    id: 'clone-source-code'
  - name: gcr.io/cloud-builders/git
    args: [ 'checkout', 'cicd' ]
    id: 'check-out-source-code'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'ls' ]
    dir: '$REPO_NAME'
    id: 'list-dir-before'
  - name: gcr.io/cloud-builders/gradle:5.6.2-jdk-8
    args: [ 'assemble' ]
    dir: '$REPO_NAME'
    id: 'build-jar'
  - name: gcr.io/cloud-builders/gsutil
    args: [ 'cp', '*.jar', 'gs://${_DATAFLOW_JAR_BUCKET}/composer-builds/dlp-rdb-bq-import-dataflow.jar' ]
    dir: '$REPO_NAME/build/libs'
    id: 'copy-jar'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'ls' , 'build-pipeline' ]
    dir: '$REPO_NAME'
    id: 'list-dir'
  #  - name: gcr.io/cloud-builders/gsutil
  #    args: [ 'cp', '*.py', 'gs://${_DATAFLOW_JAR_BUCKET}/composer-dags' ]
  #    dir: '$REPO_NAME/workflow-dags'
  #    id: 'deploy-processing-pipeline'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'wait_for_dag_deployed.sh', '${_COMPOSER_ENV_NAME}', '${_COMPOSER_REGION}', '${_COMPOSER_DAG_NAME}', '6', '20' ]
    dir: '$REPO_NAME/build-pipeline'
    id: 'wait-for-dag-deployed-on-composer'
  - name: gcr.io/cloud-builders/gcloud
    args: [ 'composer', 'environments', 'run', '${_COMPOSER_ENV_NAME}', '--location', '${_COMPOSER_REGION}', 'trigger_dag', '--', '${_COMPOSER_DAG_NAME}', '--run_id=$BUILD_ID' ]
    id: 'trigger-pipeline-execution'
