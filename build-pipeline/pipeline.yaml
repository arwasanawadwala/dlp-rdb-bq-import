substitutions:
  _DATAFLOW_JAR_BUCKET: "${PROJECT_ID}-artifacts"
  _DATAFLOW_STAGING_BUCKET: "${PROJECT_ID}-artifacts-staging"
  _COMPOSER_REGION: 'us-central1'
  _COMPOSER_ZONE_ID: 'us-central1-a'
  _COMPOSER_ENV_NAME: 'dlp-pipeline-composer'
  _COMPOSER_DAG_NAME: 'db-import'
  _GET_COMPOSER_DAG_BUCKET: 'gcloud composer environments describe ${_COMPOSER_ENV_NAME} --location ${_COMPOSER_REGION} --format="get(config.dagGcsPrefix)"'
#
steps:
  - name: gcr.io/cloud-builders/git
    args: [ 'clone', 'https://github.com/krishnachaitanya-v/dlp-rdb-bq-import.git' ]
    id: 'clone-source-code'
#  - name: gcr.io/cloud-builders/gcloud
#    entrypoint: 'bash'
#    args: [ './env-setup/set_env.sh' ]
#    dir: '$REPO_NAME'
#    env:
#      - '_DATAFLOW_JAR_BUCKET=$_DATAFLOW_JAR_BUCKET'
#      - '_DATAFLOW_STAGING_BUCKET=$_DATAFLOW_STAGING_BUCKET'
#      - '_COMPOSER_REGION=$_COMPOSER_REGION'
#      - '_COMPOSER_ZONE_ID=$_COMPOSER_ZONE_ID'
#      - '_COMPOSER_ENV_NAME=$_COMPOSER_ENV_NAME'
#      - '_COMPOSER_DAG_NAME=$_COMPOSER_DAG_NAME'
#      - '_COMPOSER_DAG_BUCKET=$_COMPOSER_DAG_BUCKET'
#  - name: gcr.io/cloud-builders/gsutil
#    args: [ 'cp', 'set_env.sh', '/workspace/set_env.sh' ]
#    dir: '$REPO_NAME/env-setup'
#    id: 'set-build-environment'
  - name: gcr.io/cloud-builders/gradle:5.6.2-jdk-8
    args: [ 'assemble' ]
    dir: '$REPO_NAME'
    id: 'build-jar'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        eval ${_GET_COMPOSER_DAG_BUCKET} > /workspace/test.txt \
        && cp build/libs/*.jar gs://$(cat /workspace/test.txt)/dlp-rdb-bq-import-dataflow.jar
    dir: '$REPO_NAME'
    #  - name: gcr.io/cloud-builders/gcloud
    #    entrypoint: 'bash'
    #    args: [ '/workspace/set_env.sh &&', 'cp', '*.jar', 'gs://${_DATAFLOW_JAR_BUCKET}/composer-builds/dlp-rdb-bq-import-dataflow.jar' ]
    #    dir: '$REPO_NAME/build/libs'
    id: 'copy-jar'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'source /workspace/set_env.sh &&', 'composer', 'environments', 'run', '${_COMPOSER_ENV_NAME}', '--location', '${_COMPOSER_REGION}','variables', '--', '--i',
        '{gcp_project=${GCP_PROJECT_ID},
          gcp_region=${_COMPOSER_REGION},
          gcp_zone=${_COMPOSER_ZONE_ID},
          dataflow_jar_location=${_DATAFLOW_JAR_BUCKET},
          dataflow_jar_file=dlp-rdb-bq-import-dataflow.jar,
          dataflow_staging_bucket=${_DATAFLOW_STAGING_BUCKET}}' ]
    id: 'set-composer-environment'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'source /workspace/set_env.sh &&', 'cp', '*.py', 'gs://${_DATAFLOW_JAR_BUCKET}/composer-dags' ]
    dir: '$REPO_NAME/workflow-dags'
    id: 'copy-dags'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'source /workspace/set_env.sh &&', 'cp', '-r', 'gs://${_DATAFLOW_JAR_BUCKET}/composer-dags', '${${_GET_COMPOSER_DAG_BUCKET}}' ]
    dir: '$REPO_NAME/workflow-dags'
    id: 'deploy-processing-pipeline'
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: 'bash'
    args: [ '-c', 'source /workspace/set_env.sh &&', './wait_for_dag_deployed.sh', '${_COMPOSER_ENV_NAME}', '${_COMPOSER_REGION}', '${_COMPOSER_DAG_NAME}', '6', '20' ]
    dir: '$REPO_NAME/build-pipeline'
    id: 'wait-for-dag-deployed-on-composer'
  - name: gcr.io/cloud-builders/gcloud
    args: [ '-c', 'source /workspace/set_env.sh &&', 'composer', 'environments', 'run', '${_COMPOSER_ENV_NAME}', '--location', '${_COMPOSER_REGION}', 'trigger_dag', '--', '${_COMPOSER_DAG_NAME}', '--run_id=$BUILD_ID' ]
    id: 'trigger-pipeline-execution'
